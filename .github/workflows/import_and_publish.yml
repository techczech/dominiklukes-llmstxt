name: Import & Publish

on:
  push:
    branches: [ main ]
  schedule:
    - cron: "0 2 * * *"   # nightly 02:00 UTC — adjust if you want Europe/Prague
  workflow_dispatch:

permissions:
  contents: write
  pages: write
  id-token: write

concurrency:
  group: import-and-publish
  cancel-in-progress: true

jobs:
  import_normalize_build:
    runs-on: ubuntu-latest
    env:
      REPO: ${{ github.workspace }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-v1-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            pip-${{ runner.os }}-v1-

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt || true
          # Ensure runtime deps used by importers and normalizer
          pip install feedparser trafilatura markdownify python-frontmatter python-slugify rapidfuzz requests
      
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y jq

      - name: Setup Node (for Notion exporter & pagefind)
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install Node tools
        run: |
          npm ci --omit=dev || true
          npm install @notionhq/client notion-to-md pagefind

      - name: Run importers
        env:
          NOTION_TOKEN: ${{ secrets.NOTION_TOKEN }}
          NOTION_PAGE_IDS: ${{ secrets.NOTION_PAGE_IDS }}
        run: |
          set -e
          python scripts/import_wordpress.py || true
          python scripts/import_medium.py || true
          python scripts/import_substack.py || true
          node scripts/notion_export.mjs || true

      - name: Normalize & build dataset (atomic write)
        run: |
          python scripts/normalize_and_build_dataset.py

      - name: Sanity check dataset
        id: sanity
        run: |
          MANIFEST_N=$(jq -r .n_documents dataset/manifest.json)
          LINES=$(wc -l < dataset/corpus.jsonl || echo 0)
          echo "manifest=$MANIFEST_N lines=$LINES"
          if [ "$LINES" -lt "$MANIFEST_N" ]; then
            echo "ERROR: Dataset line count ($LINES) < manifest ($MANIFEST_N) — failing workflow"
            exit 1
          fi

      - name: Debug repository structure
        run: |
          echo "=== Repository contents ==="
          find . -name "*.toml" -o -name "hugo.toml" -o -name "config.toml" | head -10
          echo "=== Site directory ==="
          ls -la site/ || echo "No site directory"
          echo "=== Root directory ==="
          ls -la . | head -20

      - name: Build Hugo site
        run: |
          # Ensure Hugo is available via action
          npm i -g hugo-bin || true
          
          echo "Checking for Hugo config files..."
          
          # Check if config exists and build accordingly
          HUGO_SUCCESS=false
          
          if [ -f "site/hugo.toml" ]; then
            echo "Found site/hugo.toml, building with it"
            if hugo --minify --config site/hugo.toml --source site --destination site/public; then
              HUGO_SUCCESS=true
            fi
          elif [ -f "site/config.toml" ]; then
            echo "Found site/config.toml, building with it"
            if hugo --minify --config site/config.toml --source site --destination site/public; then
              HUGO_SUCCESS=true
            fi
          elif [ -f "hugo.toml" ]; then
            echo "Found hugo.toml, building with it"
            if hugo --minify --config hugo.toml --destination site/public; then
              HUGO_SUCCESS=true
            fi
          elif [ -f "config.toml" ]; then
            echo "Found config.toml, building with it"
            if hugo --minify --config config.toml --destination site/public; then
              HUGO_SUCCESS=true
            fi
          fi
          
          # If Hugo build failed or no config found, create basic site
          if [ "$HUGO_SUCCESS" != "true" ]; then
            echo "Hugo build failed or no config found, creating basic site structure"
            mkdir -p site/public
            echo "<h1>Content Archive</h1><p>This site contains $(wc -l < dataset/corpus.jsonl 2>/dev/null || echo 0) documents from the corpus.</p><p><a href='/static/llms.txt'>Machine-readable index (llms.txt)</a></p>" > site/public/index.html
            
            # Copy static files if they exist
            if [ -d "static" ]; then
              cp -r static/* site/public/ 2>/dev/null || true
            fi
            
            echo "Created basic site structure"
          fi

      - name: Generate Pagefind index
        run: |
          npx pagefind --site site/public || echo "Pagefind indexing failed or skipped"

      - name: Upload pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: site/public

  deploy:
    needs: import_normalize_build
    runs-on: ubuntu-latest
    steps:
      - name: Deploy to GitHub Pages
        uses: actions/deploy-pages@v4
